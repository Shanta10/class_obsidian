{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spbByxbAJAQU"
   },
   "source": [
    "1. **Introducción**: Machine Learning, que es una rama de la inteligencia artificial que se centra en la construcción de sistemas que pueden aprender de los datos. El proyecto específico mencionado es predecir la supervivencia de los pasajeros del Titanic, que es un problema de clasificación binaria (sobrevivir o no sobrevivir)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSnNImCyJKag"
   },
   "source": [
    "2. **Preparación del entorno de programación**: Aquí, el autor habla sobre las bibliotecas de Python que se utilizarán en el proyecto. Estas bibliotecas proporcionan funciones y métodos que facilitan la manipulación de datos, el análisis estadístico y la implementación de algoritmos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptXo1BxfJ432"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Se importan las librerías de Python que se van a utilizar en el programa\n",
    "\n",
    "import numpy as np # numpy es una librería para el manejo de arrays y matrices de gran tamaño y funciones matemáticas de alto nivel\n",
    "import pandas as pd  # pandas es una librería para la manipulación y análisis de datos\n",
    "from sklearn.model_selection import train_test_split  # Esta función de sklearn se utiliza para dividir arrays o matrices en subconjuntos aleatorios de entrenamiento y prueba\n",
    "from sklearn.linear_model import LogisticRegression  # LogisticRegression es un algoritmo de clasificación que se utiliza en este proyecto\n",
    "from sklearn.svm import SVC  # SVC (Support Vector Classification) es otro algoritmo de clasificación que se utiliza en este proyecto\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNeighborsClassifier es un algoritmo de clasificación basado en los k vecinos más cercanos\n",
    "\n",
    "\n",
    "#Este código importa las bibliotecas y funciones necesarias para el proyecto. Estas bibliotecas proporcionan las herramientas necesarias para manipular los datos, implementar los algoritmos de Machine Learning y dividir los datos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Cl44dcIJRER"
   },
   "source": [
    "\n",
    "3. **Importación y exploración de datos**: En esta sección, el autor describe cómo importar datos desde una fuente externa (en este caso, Kaggle) y cómo explorar estos datos. La exploración de datos es un paso crucial en cualquier proyecto de Machine Learning, ya que permite entender la estructura y las características de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loyYQEgfKI7G"
   },
   "outputs": [],
   "source": [
    "# Importar los datos desde la página de Kaggle\n",
    "url_test = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv'\n",
    "url_train = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv'\n",
    "df_test = pd.read_csv(url_test)  # Leer el archivo CSV de los datos de prueba y almacenarlo en un DataFrame de pandas\n",
    "df_train = pd.read_csv(url_train)  # Leer el archivo CSV de los datos de entrenamiento y almacenarlo en un DataFrame de pandas\n",
    "\n",
    "# Guardar los datos en un archivo local para tenerlos siempre disponibles\n",
    "dir_test = '/Users/xxx/Documents/ML/Proyectos/Titanic/titanic_test.csv'\n",
    "dir_train = '/Users/xxx/Documents/ML/Proyectos/Titanic/titanic_train.csv'\n",
    "df_test.to_csv(dir_test)  # Guardar el DataFrame de los datos de prueba en un archivo CSV\n",
    "df_train.to_csv(dir_train)  # Guardar el DataFrame de los datos de entrenamiento en un archivo CSV\n",
    "\n",
    "# Importar los datos de los archivos .csv almacenados\n",
    "df_test = pd.read_csv(dir_test)  # Leer el archivo CSV de los datos de prueba y almacenarlo en un DataFrame de pandas\n",
    "df_train = pd.read_csv(dir_train)  # Leer el archivo CSV de los datos de entrenamiento y almacenarlo en un DataFrame de pandas\n",
    "\n",
    "# Verificar la cantidad de datos que hay en los conjuntos de datos\n",
    "print('Cantidad de datos:')\n",
    "print(df_train.shape)  # Imprimir la cantidad de filas y columnas en el conjunto de datos de entrenamiento\n",
    "print(df_test.shape)  # Imprimir la cantidad de filas y columnas en el conjunto de datos de prueba\n",
    "\n",
    "# Verificar el tipo de datos contenidos en ambos conjuntos de datos\n",
    "print('Tipos de datos:')\n",
    "print(df_train.info())  # Imprimir información sobre el conjunto de datos de entrenamiento, incluyendo el tipo de datos de cada columna\n",
    "print(df_test.info())  # Imprimir información sobre el conjunto de datos de prueba, incluyendo el tipo de datos de cada columna\n",
    "\n",
    "# Verificar los datos faltantes de los conjuntos de datos\n",
    "print('Datos faltantes:')\n",
    "print(pd.isnull(df_train).sum())  # Imprimir la cantidad de datos faltantes en cada columna del conjunto de datos de entrenamiento\n",
    "print(pd.isnull(df_test).rest())  # Imprimir la cantidad de datos faltantes en cada columna del conjunto de datos de prueba\n",
    "\n",
    "# Verificar las estadísticas del conjunto de datos\n",
    "print('Estadísticas del conjunto de datos:')\n",
    "print(df_train.describe())  # Imprimir estadísticas descriptivas del conjunto de datos de entrenamiento\n",
    "print(df_test.describe())  # Imprimir estadísticas descriptivas del conjunto de datos de prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz1qd7bNJTdO"
   },
   "source": [
    "4. **Preprocesamiento de datos**: Aquí, se explica cómo preparar los datos para el análisis. Esto incluye la conversión de datos categóricos a numéricos (por ejemplo, convertir el género de los pasajeros de 'masculino' y 'femenino' a 1 y 0), el manejo de datos faltantes (por ejemplo, reemplazando los valores faltantes de la edad por la media de las edades), la creación de grupos de edades y la eliminación de columnas innecesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EC0VJevJK94B"
   },
   "outputs": [],
   "source": [
    "# Cambiar los datos de sexos a números\n",
    "df_train['Sex'].replace(['female','male'],[0,1],inplace=True)  # Reemplazar 'female' por 0 y 'male' por 1 en la columna 'Sex' del conjunto de entrenamiento\n",
    "df_test['Sex'].replace(['female','male'],[0,1],inplace=True)  # Hacer lo mismo para el conjunto de prueba\n",
    "\n",
    "# Cambiar los datos de embarque en números\n",
    "df_train['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)  # Reemplazar 'Q' por 0, 'S' por 1 y 'C' por 2 en la columna 'Embarked' del conjunto de entrenamiento\n",
    "df_test['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)  # Hacer lo mismo para el conjunto de prueba\n",
    "\n",
    "# Reemplazar los datos faltantes en la edad por la media de esta columna\n",
    "print(df_train[\"Age\"].mean())  # Imprimir la media de la columna 'Age' en el conjunto de entrenamiento\n",
    "print(df_test[\"Age\"].mean())  # Hacer lo mismo para el conjunto de prueba\n",
    "promedio = 30  # Definir el valor promedio\n",
    "df_train['Age'] = df_train['Age'].replace(np.nan, promedio)  # Reemplazar los valores faltantes en la columna 'Age' del conjunto de entrenamiento por el valor promedio\n",
    "df_test['Age'] = df_test['Age'].replace(np.nan, promedio)  # Hacer lo mismo para el conjunto de prueba\n",
    "\n",
    "# Crear varios grupos de acuerdo a bandas de las edades\n",
    "# Bandas: 0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
    "bins = [0, 8, 15, 18, 25, 40, 60, 100]  # Definir las bandas de edades\n",
    "names = ['1', '2', '3', '4', '5', '6', '7']  # Definir los nombres de los grupos\n",
    "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)  # Crear los grupos de edades en el conjunto de entrenamiento\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)  # Hacer lo mismo para el conjunto de prueba\n",
    "\n",
    "# Eliminar la columna de \"Cabin\" ya que tiene muchos datos perdidos\n",
    "df_train.drop(['Cabin'], axis = 1, inplace=True)  # Eliminar la columna 'Cabin' del conjunto de entrenamiento\n",
    "df_test.drop(['Cabin'], axis = 1, inplace=True)  # Hacer lo mismo para el conjunto de prueba\n",
    "\n",
    "# Eliminar las columnas que no se consideran necesarias para el análisis\n",
    "df_train = df_train.drop(['PassengerId','Name','Ticket'], axis=1)  # Eliminar las columnas 'PassengerId', 'Name' y 'Ticket' del conjunto de entrenamiento\n",
    "df_test = df_test.drop(['Name','Ticket'], axis=1)  # Hacer lo mismo para el conjunto de prueba\n",
    "\n",
    "# Eliminar las filas con los datos perdidos\n",
    "df_train.dropna(axis=0, how='any', inplace=True)  # Eliminar las filas con datos faltantes en el conjunto de entrenamiento\n",
    "df_test.dropna(axis=0, how='any', inplace=True)  # Hacer lo mismo para el conjunto de prueba\n",
    "\n",
    "# Verificar los datos\n",
    "print(pd.isnull(df_train).sum())  # Imprimir la cantidad de datos faltantes en cada columna del conjunto de entrenamiento\n",
    "print(pd.isnull(df_test).sum())  # Hacer lo mismo para el conjunto de prueba\n",
    "print(df_train.shape)  # Imprimir la cantidad de filas y columnas en el conjunto de entrenamiento\n",
    "print(df_test.shape)  # Hacer lo mismo para el conjunto de prueba\n",
    "print(df_test.head())  # Imprimir las primeras filas del conjunto de prueba\n",
    "print(df_train.head())  # Hacer lo mismo para el conjunto de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jsGQMw6JYw1"
   },
   "source": [
    "5. **Aplicación de algoritmos de Machine Learning**: En esta sección, el autor describe cómo implementar y entrenar tres algoritmos de Machine Learning: Regresión Logística, Máquinas de Vectores de Soporte (SVM) y Vecinos más Cercanos (KNN). Estos algoritmos se utilizan para crear modelos que pueden predecir si un pasajero sobrevivirá o no basándose en sus características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WAzgwo8LQU1"
   },
   "outputs": [],
   "source": [
    "# Separar los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
    "X = np.array()  # Crear un array con los datos de las características (todos los datos del conjunto de entrenamiento excepto la columna 'Survived')\n",
    "y = np.array(df_train['Survived'])  # Crear un array con los datos de la variable objetivo (la columna 'Survived' del conjunto de entrenamiento)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # Dividir los datos en un conjunto de entrenamiento y un conjunto de prueba\n",
    "\n",
    "# Regresión logística\n",
    "logreg = LogisticRegression()  # Crear una instancia del algoritmo de Regresión Logística\n",
    "logreg.fit(X_train, y_train)  # Entrenar el algoritmo con los datos de entrenamiento\n",
    "Y_pred = logreg.predict(X_test)  # Hacer predicciones con los datos de prueba\n",
    "print('Precisión Regresión Logística:')\n",
    "print(logreg.score(X_train, y_train))  # Imprimir la precisión del algoritmo en los datos de entrenamiento\n",
    "\n",
    "# Support Vector Machines\n",
    "svc = SVC()  # Crear una instancia del algoritmo de Máquinas de Vectores de Soporte\n",
    "svc.fit(X_train, y_train)  # Entrenar el algoritmo con los datos de entrenamiento\n",
    "Y_pred = svc.predict(X_test)  # Hacer predicciones con los datos de prueba\n",
    "print('Precisión Soporte de Vectores:')\n",
    "print(svc.score(X_train, y_train))  # Imprimir la precisión del algoritmo en los datos de entrenamiento\n",
    "\n",
    "# K neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors = 300)  # Crear una instancia del algoritmo de Vecinos más Cercanos con vecinos\n",
    "knn.fit(X_train, y_train)  # Entrenar el algoritmo con los datos de entrenamiento\n",
    "Y_pred = knn.predict(X_test)  # Hacer predicciones con los datos de prueba\n",
    "print('Precisión Vecinos más Cercanos:')\n",
    "print(knn.score(X_train, y_train))  # Imprimir la precisión del algoritmo en los datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoFYx2INJh8U"
   },
   "source": [
    "6. **Predicciones**: Aquí, se utiliza los modelos entrenados para hacer predicciones sobre un conjunto de datos de prueba. Esto permite evaluar la eficacia de los modelos en datos que no se utilizaron durante el entrenamiento.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVXWv_rbLlSD"
   },
   "outputs": [],
   "source": [
    "# Predicciones con los modelos entrenados\n",
    "\n",
    "# Predicciones con Regresión Logística\n",
    "ids = df_test['PassengerId']  # Guardar los IDs de los pasajeros del conjunto de prueba\n",
    "df_test['Age'] = df_test['Age'].astype(float)\n",
    "predictions = logreg.predict(df_test.drop('PassengerId', axis=1))  # Hacer predicciones con el modelo de Regresión Logística y los datos de prueba (excepto los IDs de los pasajeros)\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })  # Crear un DataFrame con los IDs de los pasajeros y las predicciones\n",
    "print('Predicciones Regresión Logística:')\n",
    "print(output.head())  # Imprimir las primeras filas del DataFrame de salida\n",
    "\n",
    "# Predicciones con Máquinas de Vectores de Soporte (SVM)\n",
    "predictions = svc.predict(df_test.drop('PassengerId', axis=1))  # Hacer predicciones con el modelo SVM y los datos de prueba (excepto los IDs de los pasajeros)\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })  # Crear un DataFrame con los IDs de los pasajeros y las predicciones\n",
    "print('Predicciones Soporte de Vectores:')\n",
    "print(output.head())  # Imprimir las primeras filas del DataFrame de salida\n",
    "\n",
    "# Predicciones con Vecinos más Cercanos (KNN)\n",
    "predictions = knn.predict(df_test.drop('PassengerId', axis=1))  # Hacer predicciones con el modelo KNN y los datos de prueba (excepto los IDs de los pasajeros)\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })  # Crear un DataFrame con los IDs de los pasajeros y las predicciones\n",
    "print('Predicciones Vecinos más Cercanos:')\n",
    "print(output.head())  # Imprimir las primeras filas del DataFrame de salida\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
